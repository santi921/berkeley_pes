{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempted relative import beyond top-level package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37257/1379184094.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: attempted relative import beyond top-level package"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from berkeley_pes.utils.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_rapter = \"../../data/20230414_rapter_tracks_initial.json\"\n",
    "file_libe = \"../../data/tasks_opt_trajectories_partial.json\"\n",
    "file_test = \"../../data/test_rapter.json\"\n",
    "\n",
    "df_rapter = pd.read_json(file_test)\n",
    "#print(df_rapter.shape)\n",
    "#df_libe = dd.read_json(file_libe)\n",
    "#pd.read_json(file_libe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37257/1073354614.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m write_whole_df_to_ase_xyz(\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"../../data/tasks_opt_trajectories_partial.json\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \"../../data/npz/opt_trajectories_partial.xyz\")\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_37257/3907644884.py\u001b[0m in \u001b[0;36mwrite_whole_df_to_ase_xyz\u001b[0;34m(df_file, file_out)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done loading json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/berkeley_pes/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/berkeley_pes/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mlines_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/berkeley_pes/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#write_to_npz(res, file_out_npz)\n",
    "#write_to_ase(res, file_out_ase)\n",
    "\n",
    "       \n",
    "write_whole_df_to_ase_xyz(\n",
    "    \"../../data/tasks_opt_trajectories_partial.json\", \n",
    "    \"../../data/npz/opt_trajectories_partial.xyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entering ind mode 1\n",
      "prefix=item.molecule_trajectory.item.sites.item, event=map_key, value=xyz\n",
      "prefix=item.molecule_trajectory.item.sites.item.species.item, event=start_map, value=None\n",
      "prefix=item.molecule_trajectory.item.sites.item.species.item.element, event=string, value=H\n",
      "prefix=item.molecule_trajectory.item.sites.item.species.item, event=end_map, value=None\n",
      "prefix=item.molecule_trajectory.item.sites.item.species.item.occu, event=number, value=1\n",
      "prefix=item.gradient_trajectory.item.item, event=start_array, value=None\n",
      "prefix=item.molecule_trajectory.item.sites.item.xyz, event=start_array, value=None\n",
      "prefix=item.molecule_trajectory.item.sites.item.species.item, event=start_map, value=None\n",
      "prefix=item.gradient_trajectory.item.item, event=end_array, value=None\n",
      "prefix=item.molecule_trajectory.item.sites.item.properties, event=end_map, value=None\n",
      "prefix=item.molecule_trajectory.item.sites.item, event=map_key, value=name\n",
      "prefix=item.molecule_trajectory.item.sites.item.xyz.item, event=number, value=1.7989697484\n",
      "prefix=item.molecule_trajectory.item.sites.item.properties, event=end_map, value=None\n",
      "prefix=item.molecule_trajectory.item.sites.item.species.item, event=map_key, value=occu\n",
      "prefix=item.gradient_trajectory.item.item.item, event=number, value=-0.0000477995\n",
      "prefix=item.molecule_trajectory.item.sites.item.xyz.item, event=number, value=0.5057527463\n",
      "prefix=item.molecule_trajectory.item.sites.item.xyz.item, event=number, value=-1.6061283567\n",
      "prefix=item.molecule_trajectory.item.sites.item.species, event=start_array, value=None\n",
      "prefix=item.molecule_trajectory.item.sites.item.xyz.item, event=number, value=2.9720966113\n",
      "prefix=item.molecule_trajectory.item.sites.item.species.item.element, event=string, value=C\n",
      "prefix=item.molecule_trajectory.item.sites.item.species.item, event=end_map, value=None\n",
      "prefix=item.molecule_trajectory.item.sites.item.xyz.item, event=number, value=6.1719663743\n",
      "14414\n",
      "579636\n",
      "23368668\n",
      "23368668\n",
      "7789556\n",
      "14414\n",
      "14414\n",
      "[ 5.  5. 82. ... 28. 14.  6.]\n",
      "entering ind mode 0\n",
      "0\n",
      "2755\n",
      "127410\n",
      "127410\n",
      "42470\n",
      "100\n",
      "100\n",
      "[  5.   5.  82.  16. 132.   2.  33.  19.  27.  24.  11. 117.  44.  59.\n",
      "  39.  50.  69.  15.  26.  10.   2.   4.  28.  26.   7.  54.  21.   2.\n",
      "  87.  26.  13.  27.  17.   8.  20.  21.  80.  59.  14.  32.  27.   9.\n",
      "  34.   5.  23.  14.   1.   3.   1.   3.   3.   4.  30.  19.  14.  52.\n",
      "   3.   2.  55.  80.  79.   2.  26.   2.  24.   2.   9.   3.   2.   4.\n",
      "  13.   2.   2.   2.  47.  33.  25.   4.  24.  19.  19.  27.  13.  26.\n",
      "  23.  46.   9.   4. 145.  20.  49.   9.  16.   5.  51.  63.  94.  24.\n",
      "   4.  69.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ijson\n",
    "import numpy as np \n",
    "\n",
    "def parse_json(json_filename, mode=\"normal\"):\n",
    "\n",
    "    energies_raw, energies = [], []\n",
    "    grad_unformated = []\n",
    "    xyz_unformated = []\n",
    "    element_list = []\n",
    "    atom_count = []\n",
    "    element_count = []\n",
    "\n",
    "    with open(json_filename, 'rb') as input_file:\n",
    "        # load json iteratively\n",
    "        parser = ijson.parse(input_file)\n",
    "        ind_track, atom_count_temp = 0, 0\n",
    "        ind_current = -1\n",
    "        ind_mode = -1\n",
    "        check_ind = 0\n",
    "        trigger_count = 0 \n",
    "        for prefix, event, value in parser:\n",
    "            check_ind +=1\n",
    "            if check_ind % 10000000 == 0:\n",
    "                print('prefix={}, event={}, value={}'.format(prefix, event, value))\n",
    "\n",
    "            if mode==\"alt\": \n",
    "                #pass\n",
    "                \n",
    "                if prefix[0:13] == \"item.molecule\":\n",
    "                    if ind_mode == -1 and event == \"start_array\":\n",
    "                        try:\n",
    "                            ind_current = int(prefix.split(\".\")[1])\n",
    "                            ind_mode = 0\n",
    "                            print(\"entering ind mode 0\")\n",
    "                        except: \n",
    "                            trigger = False\n",
    "                            ind_mode = 1    \n",
    "                            print(\"entering ind mode 1\")\n",
    "                    \n",
    "                    if value == None and event == \"end_map\" and prefix==\"item.molecule\":\n",
    "                        trigger = True\n",
    "                        trigger_count +=1\n",
    "\n",
    "                    elif event == 'number':\n",
    "                        if \"xyz\" in prefix.split(\".\"):\n",
    "                            #print('prefix={}, event={}, value={}'.format(prefix, event, value))\n",
    "                            xyz_unformated.append(float(value))\n",
    "\n",
    "                    elif event == 'string': \n",
    "                        #print('prefix={}, event={}, value={}'.format(prefix, event, value))\n",
    "                        if \"element\" in prefix.split(\".\"):\n",
    "                            #print('prefix={}, event={}, value={}'.format(prefix, event, value))\n",
    "                            element_list.append(str(value))\n",
    "                            #print(value)\n",
    "                            if trigger:\n",
    "                                #print(\"triggered\")\n",
    "                                atom_count.append(atom_count_temp)\n",
    "                                element_count.append(len(set(element_list)))\n",
    "                                atom_count_temp = 1\n",
    "                                trigger = False\n",
    "\n",
    "                            else: \n",
    "                                atom_count_temp += 1\n",
    "                \n",
    "                if value!=None:\n",
    "                    if \"gradient\" in prefix.split(\".\"):\n",
    "                        if event == 'number':\n",
    "                            grad_unformated.append(float(value))\n",
    "                \n",
    "                    if prefix=='item.energy':\n",
    "                        if event == 'number':\n",
    "                            energies_raw.append(float(value))\n",
    "                \n",
    "            else: \n",
    "                if value is not None:\n",
    "                    if event == \"string\":\n",
    "                        if \"formula_alphabetical\" in prefix.split(\".\"): \n",
    "                            # sum all integers in string\n",
    "                            elements = value.split()\n",
    "                            # strip elements of alphabetical characters\n",
    "                            elements = [element.strip(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\") for element in elements]\n",
    "                            #strip lowercase letters\n",
    "                            elements = [element.strip(\"abcdefghijklmnopqrstuvwxyz\") for element in elements]\n",
    "                            #print(elements)\n",
    "                            num_atoms = sum(map(int, elements))\n",
    "                            element_count.append(num_atoms)\n",
    "\n",
    "                    if event == 'number':\n",
    "                        if \"energy_trajectory\" in prefix.split(\".\"):\n",
    "                            energies_raw.append(float(value))\n",
    "\n",
    "                    if event == 'number':\n",
    "                        if \"gradient_trajectory\" in prefix.split(\".\"):\n",
    "                            #print('prefix={}, event={}, value={}'.format(prefix, event, value))\n",
    "                            grad_unformated.append(float(value))\n",
    "\n",
    "                if \"molecule_trajectory\" in prefix.split(\".\"):\n",
    "                    #if prefix[0:13] == \"item.molecule\":                    \n",
    "                    if ind_mode == -1 and event == \"start_array\":\n",
    "                        try:\n",
    "                            ind_current = int(prefix.split(\".\")[1])\n",
    "                            ind_mode = 0\n",
    "                            print(\"entering ind mode 0\")\n",
    "                        except: \n",
    "                            trigger = False\n",
    "                            ind_mode = 1    \n",
    "                            print(\"entering ind mode 1\")\n",
    "                                        \n",
    "                    if ind_mode == 0:\n",
    "                        #print('prefix={}, event={}, value={}'.format(prefix, event, value))\n",
    "\n",
    "                        if event == 'number':\n",
    "                            if \"xyz\" in prefix.split(\".\"):\n",
    "                                #print('prefix={}, event={}, value={}'.format(prefix, event, value))\n",
    "                                xyz_unformated.append(float(value))\n",
    "\n",
    "                        if event == 'string': \n",
    "                            #print('prefix={}, event={}, value={}'.format(prefix, event, value))\n",
    "                            if \"name\" in prefix.split(\".\"):\n",
    "                                element_list.append(str(value))\n",
    "                                ind_current = int(prefix.split(\".\")[1])\n",
    "                                #print(ind_current, ind_track)\n",
    "                                if ind_current != ind_track:\n",
    "                                    ind_track = int(ind_current)\n",
    "                                    atom_count.append(atom_count_temp)\n",
    "                                    atom_count_temp = 1\n",
    "                                else: \n",
    "                                    atom_count_temp += 1\n",
    "                \n",
    "                    if ind_mode == 1:\n",
    "                        #print('prefix={}, event={}, value={}'.format(prefix, event, value))\n",
    "                        if value == None and event == \"end_array\" and prefix==\"item.molecule_trajectory\":\n",
    "                            trigger = True\n",
    "                            trigger_count +=1\n",
    "\n",
    "                        if event == 'number':\n",
    "                            if \"xyz\" in prefix.split(\".\"):\n",
    "                                xyz_unformated.append(float(value))\n",
    "\n",
    "                        if event == 'string': \n",
    "                            if \"name\" in prefix.split(\".\"):\n",
    "                                element_list.append(str(value))\n",
    "                                if trigger:\n",
    "                                    atom_count.append(atom_count_temp)\n",
    "                                    atom_count_temp = 1\n",
    "                                    trigger = False\n",
    "                                else: \n",
    "                                    atom_count_temp += 1\n",
    "\n",
    "    if ind_mode == 0:                \n",
    "        atom_count.append(atom_count_temp)\n",
    "    else:\n",
    "        atom_count.append(atom_count_temp)\n",
    "\n",
    "    print(trigger_count) \n",
    "    print(len(energies_raw))\n",
    "    print(len(grad_unformated))\n",
    "    print(len(xyz_unformated))\n",
    "    print(len(element_list))\n",
    "    print(len(atom_count)) #\n",
    "    print(len(element_count)) \n",
    "\n",
    "    grad_unformated = np.array(grad_unformated)\n",
    "    grad_formated = grad_unformated.reshape(-1, 3)\n",
    "    xyz_unformated = np.array(xyz_unformated)\n",
    "    xyz_formated = xyz_unformated.reshape(-1, 3)\n",
    "    atom_count = np.array(atom_count)\n",
    "    frames_per_mol = atom_count / element_count\n",
    "    \n",
    "    #print(frames_per_mol)\n",
    "    grad_format = np.split(grad_formated, np.cumsum(atom_count)[:-1])\n",
    "    xyz_format = np.split(xyz_formated, np.cumsum(atom_count)[:-1])\n",
    "    element_list = np.split(element_list, np.cumsum(atom_count)[:-1]) #\n",
    "    \n",
    "    #energies = np.split(energies, np.cumsum(frames_per_mol)[:-1])\n",
    "    # split energies into frames per molecule\n",
    "    running_start = 0\n",
    "    for i in range(len(frames_per_mol)):\n",
    "        energies.append(energies_raw[running_start:running_start+int(frames_per_mol[i])])\n",
    "        #energies.append(energies_raw[i*int(frames_per_mol[i]):(i+1)*int(frames_per_mol[i])])\n",
    "        running_start += int(frames_per_mol[i])\n",
    "    xyz_format = [array.reshape(int(frames_per_mol[ind_frame]), element_count[ind_frame], 3) for ind_frame, array in enumerate(xyz_format)]\n",
    "    grad_format = [array.reshape(int(frames_per_mol[ind_frame]), element_count[ind_frame], 3) for ind_frame, array in enumerate(grad_format)]\n",
    "    element_list = [array.reshape(int(frames_per_mol[ind_frame]), element_count[ind_frame]) for ind_frame, array in enumerate(element_list)]\n",
    "\n",
    "    data = {\n",
    "        \"energies\": energies,\n",
    "        \"grads\": grad_format,\n",
    "        \"xyz\": xyz_format,\n",
    "        \"elements\": element_list,\n",
    "        \"frames_per_mol\": frames_per_mol,\n",
    "        \"atom_count\": atom_count\n",
    "    }\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # running\n",
    "    data = parse_json('../../data/20230414_rapter_tracks_initial.json')\n",
    "    #data = parse_json('../../data/tasks_opt_trajectories_partial.json', mode=\"alt\")\n",
    "    data_test = parse_json('../../data/test_rapter.json') # works\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def write_whole_df_to_ase_xyz(dict_info, file_out): \n",
    "    \"\"\"\n",
    "    Takes a dataframe and writes it to a npz file\n",
    "    \"\"\"\n",
    "    energies = dict_info[\"energies\"]\n",
    "    grads_list = dict_info[\"grads\"]\n",
    "    xyzs_list = dict_info[\"xyz\"]\n",
    "    elements_list = dict_info[\"elements\"]\n",
    "    frame_count_global = 0 \n",
    "    with open(file_out, \"w\") as f:    \n",
    "        for ind_frame, (energies_frame, grads_frame, xyzs_frame, elements_frame) in enumerate(zip(energies, grads_list, xyzs_list, elements_list)):\n",
    "            #print(ind_frame, len(energies_frame))\n",
    "            for ind_mol, (energy, grad, xyz, elements) in enumerate(zip(energies_frame, grads_frame, xyzs_frame, elements_frame)):\n",
    "                frame_count_global += 1\n",
    "                n_atoms = len(elements)\n",
    "                #print(elements)\n",
    "                f.write(str(n_atoms) + \"\\n\")\n",
    "                f.write(\"Properties=species:S:1:pos:R:3:forces:R:3 energy={} free_energy={} pbc=\\\"F F F\\\"\\n\".format(energy, energy))\n",
    "                for ind_atom, (xyz, grad) in enumerate(zip(xyz, grad)): \n",
    "                    #print(elements[0])\n",
    "                    f.write(\"{:2} {:15.8} {:15.8} {:15.8} {:15.8} {:15.8} {:15.8}\\n\".format(elements[ind_atom], xyz[0], xyz[1], xyz[2], grad[0], grad[1], grad[2]))\n",
    "\n",
    "    \n",
    "    print(\"Wrote {} frames to {}\".format(frame_count_global, file_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2755\n"
     ]
    }
   ],
   "source": [
    "frame_count = 0 \n",
    "for i in range(len(data_test[\"energies\"])):\n",
    "    frame_count += len(data_test[\"energies\"][i])\n",
    "print(frame_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 2755 frames to ../../data/npz/test_parser.xyz\n",
      "Wrote 579636 frames to ../../data/npz/20230414_rapter_tracks_initial.xyz\n"
     ]
    }
   ],
   "source": [
    "write_whole_df_to_ase_xyz(data_test, \"../../data/npz/test_parser.xyz\")\n",
    "write_whole_df_to_ase_xyz(data, \"../../data/npz/20230414_rapter_tracks_initial.xyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read with ase \n",
    "from ase.io import read\n",
    "test_out = read(\"../../data/npz/20230414_rapter_tracks_initial.xyz\", index=\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "579636"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_out) #whoo!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allegro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
